# orchestrator/deployment.py

import json
import time
import tempfile
from pathlib import Path

from .helpers import (
    print_success,
    print_error,
    print_info,
    print_warning,
    print_header,
    run_gh_api,
    read_file_lines,
    append_to_file,
    load_json_file,
    run_command,
    disable_workflow,
    enable_workflow,
    CONFIG_FILE,
    TOKEN_CACHE_FILE,
    FORKED_REPOS_FILE,
    WORKFLOWS_ENABLED_FILE
)
from .collaboration import sync_fork_with_upstream
from .utils import check_actions_usage


def enable_actions_on_repo(repo_path: str, token: str) -> bool:
    """Mengaktifkan GitHub Actions pada repositori."""
    print_info("üîß Enabling GitHub Actions on repository...")
    
    # PERBAIKAN: Menggunakan --raw-field untuk mengirim boolean dengan benar dan mencegah error 422
    result = run_gh_api(
        f"api -X PUT repos/{repo_path}/actions/permissions --raw-field enabled=true --raw-field allowed_actions=all",
        token,
        timeout=30
    )
    
    if result["success"]:
        print_success("‚úÖ Actions enabled on repository")
        time.sleep(2)
        return True
    else:
        # Menambahkan penanganan error yang lebih baik jika dijalankan pada akun personal
        error_msg = result.get('error', '').lower()
        if "must be an organization" in error_msg:
             print_info("‚ÑπÔ∏è  Skipping for personal account (not required)")
             return True
        print_warning(f"‚ö†Ô∏è Failed to enable Actions: {result.get('error')}")
        return False


def deploy_to_github():
    """Men-deploy file workflow ke repositori target."""
    print_header("10. DEPLOY TO GITHUB")
    config = load_json_file(CONFIG_FILE)
    token_cache = load_json_file(TOKEN_CACHE_FILE)
    forked_users = read_file_lines(FORKED_REPOS_FILE)
    
    if not config or not token_cache:
        print_error("Konfigurasi atau cache token tidak lengkap.")
        return

    total_accounts = len(token_cache)
    print_info(f"üìä Memulai proses untuk {total_accounts} akun...")

    workflow_file = "datagram-runner.yml"
    workflow_source = Path(__file__).parent.parent / ".github" / "workflows" / workflow_file
    if not workflow_source.exists():
        print_error(f"File workflow tidak ditemukan: {workflow_source}")
        return

    print("Pilih target deployment:\n 1. Main repo saja\n 2. Semua forked repos\n 3. Main + semua forks")
    choice = input("\nPilihan (1/2/3): ").strip()

    targets = []
    if choice in ['1', '3']:
        targets.append({'repo': f"{config['main_account_username']}/{config['main_repo_name']}", 'token': config['main_token'], 'username': config['main_account_username']})
    if choice in ['2', '3']:
        targets.extend([
            {'repo': f"{u}/{config['main_repo_name']}", 'token': t, 'username': u}
            for t, u in token_cache.items() if u in forked_users
        ])

    if not targets or input(f"\nüéØ Akan deploy ke {len(targets)} repo. Lanjutkan? (y/n): ").lower() != 'y':
        print_warning("Operasi dibatalkan.")
        return

    workflow_content = workflow_source.read_text(encoding='utf-8')
    workflows_enabled = read_file_lines(WORKFLOWS_ENABLED_FILE)
    success_count = 0
    failed_count = 0
    main_username = config['main_account_username']

    for i, target in enumerate(targets, 1):
        repo_path, token, username = target['repo'], target['token'], target['username']
        print(f"\n{'='*47}\n[{i}/{len(targets)}] Deploying to: {repo_path}\n{'='*47}")

        if username != main_username:
            print_info("üîÑ Menyinkronkan fork...")
            if sync_fork_with_upstream(repo_path, token):
                print_success("‚úÖ Fork berhasil disinkronkan")
            else:
                print_warning("‚ö†Ô∏è Sinkronisasi fork gagal, melanjutkan deployment...")
            time.sleep(2)

        enable_actions_on_repo(repo_path, token)

        with tempfile.TemporaryDirectory() as temp_dir_str:
            temp_dir = Path(temp_dir_str)
            try:
                print_info("üì• Cloning repository...")
                clone_cmd = f"git clone https://{token}@github.com/{repo_path}.git ."
                clone_result = run_command(clone_cmd, cwd=temp_dir, timeout=120)
                if clone_result.returncode != 0:
                    print_error(f"‚ùå Clone failed: {clone_result.stderr}")
                    failed_count += 1
                    continue

                workflow_dir = temp_dir / ".github" / "workflows"
                workflow_dir.mkdir(parents=True, exist_ok=True)
                (workflow_dir / workflow_file).write_text(workflow_content, encoding='utf-8')
                print_success(f"‚úÖ Workflow file written.")

                print_info("üì§ Committing and pushing...")
                run_command("git config user.name 'Datagram Bot'", cwd=temp_dir)
                run_command("git config user.email 'bot@datagram.local'", cwd=temp_dir)
                run_command("git add .", cwd=temp_dir)
                commit_result = run_command('git commit -m "Deploy Datagram workflow"', cwd=temp_dir)
                
                if "nothing to commit" in commit_result.stdout.lower():
                    print_info("‚ÑπÔ∏è No changes to commit.")
                    success_count += 1
                    continue
                
                print_info("üîí Disabling workflow before push...")
                disable_workflow(repo_path, token, workflow_file)
                time.sleep(2)

                push_result = run_command(f"git push", cwd=temp_dir, timeout=120)
                if push_result.returncode == 0:
                    print_success("‚úÖ Push successful")
                    if repo_path not in workflows_enabled:
                        append_to_file(WORKFLOWS_ENABLED_FILE, repo_path)
                    success_count += 1
                else:
                    print_error(f"‚ùå Push failed: {push_result.stderr}")
                    failed_count += 1

            except Exception as e:
                print_error(f"‚ùå Error during deployment: {str(e)}")
                failed_count += 1
            time.sleep(2)

    print_success(f"\n{'='*47}")
    print_success(f"‚úÖ Deployment selesai!")
    print_info(f"   Berhasil: {success_count}, Gagal: {failed_count}, Total: {len(targets)}")
    print_success(f"{'='*47}")


def wait_for_workflow_completion(repo_path: str, token: str, run_id: int, timeout: int = 21600) -> bool:
    """
    Menunggu hingga workflow run selesai (completed).
    """
    start_time = time.time()
    poll_interval = 30
    
    print_info(f"‚è≥ Menunggu workflow run #{run_id} selesai...")
    
    while (time.time() - start_time) < timeout:
        result = run_gh_api(
            f"api repos/{repo_path}/actions/runs/{run_id}",
            token,
            timeout=30
        )
        
        if not result["success"]:
            print_warning(f"‚ö†Ô∏è Gagal mengecek status: {result.get('error')}")
            time.sleep(poll_interval)
            continue
        
        try:
            run_data = json.loads(result["output"])
            status = run_data.get("status", "")
            conclusion = run_data.get("conclusion", "")
            
            if status == "completed":
                if conclusion == "success":
                    print_success(f"‚úÖ Workflow selesai dengan status: {conclusion}")
                else:
                    print_warning(f"‚ö†Ô∏è Workflow selesai dengan status: {conclusion}")
                return True
            
            elapsed = int(time.time() - start_time)
            print_info(f"   Status: {status} | Elapsed: {elapsed//60}m {elapsed%60}s")
            
        except (json.JSONDecodeError, KeyError) as e:
            print_warning(f"‚ö†Ô∏è Error parsing workflow status: {str(e)}")
        
        time.sleep(poll_interval)
    
    print_error(f"‚ùå Timeout: Workflow tidak selesai dalam {timeout//60} menit")
    return False


def invoke_workflow_trigger():
    """Memicu workflow di repositori target secara berurutan per akun."""
    print_header("11. TRIGGER WORKFLOW (SEQUENTIAL)")
    config = load_json_file(CONFIG_FILE)
    token_cache = load_json_file(TOKEN_CACHE_FILE)
    forked_users = read_file_lines(FORKED_REPOS_FILE)
    
    if not config or not token_cache:
        print_error("Konfigurasi atau cache token tidak lengkap.")
        return

    total_accounts = len(token_cache)
    print_info(f"üìä Memulai proses untuk {total_accounts} akun...")

    print("Pilih target:\n 1. Main repo saja\n 2. Semua forked repos\n 3. Main + semua forks")
    choice = input("\nPilihan (1/2/3): ").strip()
    
    targets = []
    if choice in ['1', '3']:
        targets.append({
            'repo': f"{config['main_account_username']}/{config['main_repo_name']}", 
            'token': config['main_token'],
            'username': config['main_account_username']
        })
    if choice in ['2', '3']:
        targets.extend([
            {
                'repo': f"{u}/{config['main_repo_name']}", 
                'token': t,
                'username': u
            }
            for t, u in token_cache.items() if u in forked_users
        ])

    if not targets:
        print_warning("Tidak ada target yang dipilih.")
        return

    workflow_file = "datagram-runner.yml"
    billing_threshold = 1800
    success_count = 0
    failed_count = 0
    
    print_info(f"\nüöÄ Akan memicu workflow untuk {len(targets)} akun secara BERURUTAN")
    print_warning(f"‚ö†Ô∏è Ambang batas billing: {billing_threshold} menit")
    
    if input("\nLanjutkan? (y/n): ").lower() != 'y':
        print_warning("Operasi dibatalkan.")
        return

    for i, target in enumerate(targets, 1):
        repo_path = target['repo']
        token = target['token']
        username = target['username']
        
        print(f"\n{'='*50}")
        print(f"[{i}/{len(targets)}] Processing: {username}")
        print('='*50)
        
        print_info("üìä Mengecek penggunaan Actions...")
        usage_minutes = check_actions_usage(username, token)
        print_info(f"   Total menit terpakai: {usage_minutes}/{billing_threshold}")
        
        if usage_minutes >= billing_threshold:
            print_warning(f"‚ö†Ô∏è PERINGATAN: Penggunaan Actions ({usage_minutes} menit) melebihi threshold!")
            if input(f"   Tetap lanjutkan untuk {username}? (y/n): ").lower() != 'y':
                print_warning(f"‚è≠Ô∏è Melewati {username}")
                failed_count += 1
                continue
        
        print_info("üîì Enabling workflow...")
        if not enable_workflow(repo_path, token, workflow_file):
            print_error("‚ùå Gagal enable workflow")
            failed_count += 1
            continue
        
        time.sleep(3)
        
        print_info(f"üöÄ Memicu workflow untuk {repo_path}...")
        trigger_result = run_gh_api(
            f"api -X POST repos/{repo_path}/actions/workflows/{workflow_file}/dispatches -f ref=main",
            token,
            timeout=30
        )
        
        if not trigger_result["success"]:
            print_error(f"‚ùå Gagal memicu workflow: {trigger_result.get('error')}")
            failed_count += 1
            continue
        
        print_success("‚úÖ Workflow berhasil dipicu")
        
        time.sleep(10)
        
        print_info("üîç Mencari workflow run yang baru saja dipicu...")
        runs_result = run_gh_api(
            f"api repos/{repo_path}/actions/runs?per_page=1",
            token,
            timeout=30
        )
        
        if not runs_result["success"]:
            print_error(f"‚ùå Gagal mengambil workflow runs: {runs_result.get('error')}")
            failed_count += 1
            continue
        
        try:
            runs_data = json.loads(runs_result["output"])
            workflow_runs = runs_data.get("workflow_runs", [])
            
            if not workflow_runs:
                print_error("‚ùå Tidak ada workflow run ditemukan")
                failed_count += 1
                continue
            
            run_id = workflow_runs[0].get("id")
            if not run_id:
                print_error("‚ùå Run ID tidak valid")
                failed_count += 1
                continue
            
            print_info(f"üéØ Monitoring workflow run ID: {run_id}")
            
            if wait_for_workflow_completion(repo_path, token, run_id):
                print_info("üîí Disabling workflow after completion...")
                disable_workflow(repo_path, token, workflow_file)
                
                success_count += 1
                print_success(f"‚úÖ Akun {username} selesai\n")
            else:
                print_error(f"‚ùå Akun {username} gagal atau timeout\n")
                failed_count += 1
            
        except (json.JSONDecodeError, KeyError, IndexError) as e:
            print_error(f"‚ùå Error parsing workflow runs: {str(e)}")
            failed_count += 1
            continue
        
        if i < len(targets):
            print_info("‚è∏Ô∏è Delay 5 detik sebelum akun berikutnya...")
            time.sleep(5)

    print_success(f"\n{'='*50}")
    print_success(f"‚úÖ Proses selesai!")
    print_info(f"   Berhasil: {success_count}, Gagal/Dilewati: {failed_count}, Total: {len(targets)}")
    print_success('='*50)


def show_workflow_status():
    """Menampilkan status 3 workflow run terakhir."""
    print_header("12. SHOW WORKFLOW STATUS")
    config = load_json_file(CONFIG_FILE)
    token_cache = load_json_file(TOKEN_CACHE_FILE)
    forked_users = read_file_lines(FORKED_REPOS_FILE)
    
    if not config or not token_cache:
        print_error("Konfigurasi atau cache token tidak lengkap.")
        return

    total_accounts = len(token_cache)
    print_info(f"üìä Memulai proses untuk {total_accounts} akun...")

    print("Pilih target:\n 1. Main repo saja\n 2. Semua forked repos\n 3. Main + semua forks")
    choice = input("\nPilihan (1/2/3): ").strip()
    
    targets = []
    if choice in ['1', '3']:
        targets.append({
            'repo': f"{config['main_account_username']}/{config['main_repo_name']}", 
            'token': config['main_token']
        })
    if choice in ['2', '3']:
        targets.extend([
            {'repo': f"{u}/{config['main_repo_name']}", 'token': t} 
            for t, u in token_cache.items() if u in forked_users
        ])

    if not targets:
        print_warning("Tidak ada target yang dipilih.")
        return
    
    print_info(f"\nüìä Checking workflow status untuk {len(targets)} repos...\n")

    success_count = 0
    failed_count = 0

    for i, target in enumerate(targets, 1):
        repo_path = target['repo']
        token = target['token']
        
        print(f"{'='*47}\n[{i}/{len(targets)}] {repo_path}\n{'='*47}")
        result = run_gh_api(
            f"api repos/{repo_path}/actions/runs --jq '.workflow_runs[:3] | .[] | \"\\(.status) | \\(.conclusion // \"running\") | \\(.created_at)\"'",
            token, 
            timeout=30
        )
        
        if result["success"] and result["output"]:
            for run in result["output"].strip().split("\n"):
                print(f"  {run}")
            success_count += 1
        elif not result["output"]:
             print("  ‚ÑπÔ∏è No workflow runs found")
             success_count += 1
        else:
            print_error(f"  ‚ùå Failed to fetch status: {result.get('error')}")
            failed_count += 1
        print()
        time.sleep(1)

    print_success(f"\n{'='*47}")
    print_success(f"‚úÖ Proses selesai!")
    print_info(f"   Berhasil: {success_count}, Gagal: {failed_count}, Total: {len(targets)}")
    print_success(f"{'='*47}")
